# Data Engineer (Desarrollador BigData)

## Otros Nombres

Data Engineer (EN), Big Data Engineer (EN), Ingeniero de Datos, Desarrollador Big Data, Engenheiro de dados (PT, BR)

## Descripción

Profesional Ingeniero de Datos y desarrollador de Big Data, encargado de diseñar, construir, gestionar y mantener los datos y la infraestructura necesaria para almacenarlos y procesarlos, necesaria para gestionar y procesar información de manera eficiente y confiable. Este profesional habilita la recopilación, procesamiento y uso efectivo de los datos. Construyen la base tecnológica para que los científicos de datos y analistas puedan realizar sus tareas. Por lo tanto, son los responsables de mantener sistemas de Datos o Big Data escalables, con alta disponibilidad y rendimiento, integrando nuevas tecnologías y desarrollando el software necesario. Responsable de definir cómo gestionar, organizar, transformar y almacenar los datos necesarios en la organización de una forma óptima para todos los interesados. 

## Formación principal y académica

Titulación en Ingeniería Informática, Ingeniería de Sistemas, o Licenciados en Matemáticas u otras ingenierías con experiencia significativa en programación. 

## Formación secundaria

Máster o titulación de posgrado en temas relacionados con Data Science, Big Data y/o DevOps, Data & Cloud
Engineer, Inteligencia Artificial y Machine Learning; o en su defecto experiencia demostrable en estos temas. Ejemplos de certificaciones: Google Cloud Professional Data Engineer Certification, AWS Certified Data Engineer.

## Supervisión o liderazgo

No cuenta con personal a su cargo. 

## Conocimientos y competencias

Debe tener los siguientes conocimientos y competencias con la profundidad dependiente del nivel de seniority requerido:

1. **Informática**: Tener conocimientos informáticos. Deseable también matemáticos y estadísticos.  
2. **Programación**: Saber programar en lenguajes de scripting como Perl; o lenguajes como Python , R, Spark o Scala. 
3. **Automatización**; Conocimientos en automatización, scripting y en sistemas Unix/Linux. 
4. **Gobierno de Datos**: Conocer sobre Gobierno de datos (Data Mesh, etc.), linaje de datos y seguridad de datos. 
5. **Arquitectura de Datos**: Debe tener conocimientos esenciales de diseño y desarrollo de sistemas de arquitectura de datos. Buen conocimiento de la Arquitectura Lambda, junto con sus ventajas y desventajas.
6. **Ingesta de datos**: Experiencia y conocimiento con la extracción e integración de datos (recopilar, combinar y unificar datos) de múltiples fuentes de datos.
7. **Arquitectura de Eventos**: Conocimientos en sistemas de mensajería, colas, programación orientada a eventos (arquitectura basada en eventos EDA, Pub/Sub).
8. **Base de Datos**: Debe dominar el procesamiento de datos (Data Base, DM, Data warehouse), que incluye implementación y manipulación de bases de datos relacionales (SQL, PL/SQL) y no relacionales (NoSQL). 
9. Comprensión competente de los principios de computación distribuida. 
10. **Transformación y procesamiento de Datos**: Conocimiento y uso de herramientas de Big Data y explotación de datos en transformación y procesamiento de datos.
11. **Análisis de Datos y Ciencia de Datos**: Conocimientos en Big Data, Machine Learning, Deep Learning, Data wrangling, Data mining, Data Lake, Data Workflow, Procesos ETL, data munging o data tyding.
12. **Visualización y Reportería**: La capacidad para implementar tecnologías de gestión de datos, reportería y elaboración de informes como el uso de herramientas de BI y visualización de datos.
13. **Cloud**: Conocimientos en infraestructuras Cloud (Azure, AWS y/o Google Cloud Platform/GCP).
14.	**Trabajo en Equipo**: Sentido de responsabilidad, compromiso y capacidad de trabajo en equipo. 

## Responsabilidades y funciones

1. Construir y mejorar Stack tecnológico para Big Data y apoyo en la planificación de soluciones de Big Data. 
2. Programar aplicaciones distribuidas que manejen un gran volumen de datos con tecnologías/framework como Hadoop o Apache Spark. 
3. Identificación y consultas en fuentes de datos ejecutando operaciones sobre bases de datos con SQL y NoSQL. 
4. Ejecución del flujo de datos. Diseño e implementación de flujos de captura y tratamiento de datos masivos y/o en tiempo real. 
5. Encadenar las rutinas y los procesos a través de redes de pipelines para automatizar su principal tarea: ETL (Extract, Transform, Load). Automatizar tareas y pipelines que almacenan y procesan datos en formatos y tecnologías apropiadas
6. Garantizar la accesibilidad, precisión y seguridad de los datos. 
7. Apoyar y facilitar el trabajo a analistas y científicos de datos, así como a negocio. 
8. Estimar esfuerzo de desarrollo de componentes y tareas además de colaborar con la planificación de trabajo.
9. En el trabajo orientado a equipo, aunque trabajará la mayor parte del tiempo en su campo de experticia, debe desenvolverse en otros temas, tareas y actividades en función de colaborar con el equipo, apoyar en diferentes tipos de actividades para sumar capacidad, cumplir con las entregas del equipo, evitar los cuellos de botella y colaborar en solucionar problemas del equipo.
10. Solución de Problemas y Mejoras a procesos
11. Documentar Metadatos.

## Tecnologías

La tecnología dependerá de los requisitos del puesto. La tecnología general relacionada es:
- Operating System: Unix, Linux,  Windows, Mac OS.
- SQL Data Base: Oracle, MariaDB, MySQL, PostgreSQL, etc.
- NoSQL Data Base: MongoDB, Redis, Cassandra, HBase, etc.
- Big Data querying tools: Pig, Hive, Impala, etc.
- Cloud Computing: Google Cloud Platform, AWS, Asure, etc.
- BigData engine: Spark (Spark/Scala/HDFS/Hive, Python, SQL, Shell).
- BigData distributed framework: Hadoop (Hadoop, Spark,  HDFS , Map Reduce, Yarn, PIG, HIVE, HBase, Mahout, Spark MLLib, Solar, Lucene, Zookeeper, Oozie ).
- Automation tools: Ansible, Control M, etc.
- ETL tools: Apache Flume, Apache Sqoop, Apache HBase, Apache Hive, Apache Oozie, Apache Phoenix, Apache Pig, Apache ZooKeeper.
- Event & Message Brokers: Kafka, RabbitMQ, etc.
- Big Data Machine Learning toolkits: Mahout, SparkML, H2O, etc.
